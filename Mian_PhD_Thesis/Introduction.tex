In this chapter we give a brief introduction and motivation for the research work presented in this thesis. We commence by introducing the problems in random testing. We then describe the alternative approaches to overcome these problems, followed by our research goals and contributions. At the end of the chapter, we give an outline of the thesis.

\section{The Problems}
In software testing, one is often confronted with the problem of selecting a test data set because exhaustive testing is not always applicable. Test data set is a subset of domain carefully selected to test the given software. Finding an adequate test data set is a crucial process in any testing technique as it aims to represent the whole infinite domain and evaluate the given system under test (SUT) for structural or functional properties \cite{mccabe1983}. Test data generators are classified in to Pathwise, Goal-Oriented, Intellighent and Random \cite{wiki2013}. Random test data generation generate test data set randomly from the whole domain. Unlike other approaches Random approach is simple, easy to implement, fastest in execution and free from human bias \cite{Ciupa2007}. 



because of the simplicity and non-systematic nature of random testing it received high criticism. \cite{Myers2004} mentioned it as "Probably the poorest methodology of all is random-input testing...". Random testing is also blamed for providing low coverage \cite{Offutt1996}. For instance, in random testing when the statement  ``if (x == 25) then ... "  is exposed to execution then there is only one chance to be executed out of $2^\text{32}$. If x is an integer variable of 32 bit value. \cite{Godefroid2005}


\subsection{Test input data is decisive}
\subsection{Selecting Fault finding input is challenging}

\section{Our Goals}

\section{Contributions}
\subsection{Dirt Spot Sweeping Random Strategy}
\subsection{Automated Discovery of Failure Domain}
\subsection{Directed Random Plus Strategy}

\section{Thesis Outline}








%Today, the primary focus of software companies is to achieve high quality. These companies spend an estimated thirty to ninety percent of the total software development cost on testing \ref{Beizer1990}, \ref{Standards2002}. In spite of spending 

%Software testing is the process of executing a software with specific test data followed by evaluation of the results to check whether it is working according to its specification or not \ref{Sommerville2006}.
% check here if we can replace specification with oracle or not.
%The test passes if the output complies to its specification and fails otherwise. The success of testing correlates with the number of failures found in the Software Under Test (SUT): a test is more successful if it finds more faults.

%It is interesting that program testing is used to show the presence of bugs, rather than absence of bugs [6]. Therefore the SUT that passes all the tests without returning a single failure does not guarantee that there is no fault. The testing process increases however the reliability and confidence of both the developers and the users in the tested product [7] [8] [9].

%Random testing is a black-box testing technique in which the SUT is executed against ran- domly selected test data. Test results obtained are compared either against the oracle defined, using SUT specifications in the form of assertions or exceptions defined by the programming language. The rapid increase in software development in today?s modern world prompts the need for automated testing to ensure high quality. The generation of random test data is com- paratively cheap and does not require too much intellectual and computation efforts [10] [11]. It is for this reason that various researchers have recommended this strategy for incorporation in automatic testing tools [12]. YETI [13] [14], AutoTest [15] [16], QuickCheck [17], Randoop [18], JArtage [19] are a few of the most common tools based on random strategy.
