\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{subsection.1.0.1}{Software Testing}{chapter.1}% 2
\BOOKMARK [2][-]{subsection.1.0.2}{Random Testing}{subsection.1.0.1}% 3
\BOOKMARK [1][-]{section.1.1}{The Problems}{chapter.1}% 4
\BOOKMARK [2][-]{subsection.1.1.1}{Limitation of RT in the Discovery of Contagious Failures}{section.1.1}% 5
\BOOKMARK [2][-]{subsection.1.1.2}{Inability of RT to Identify Failure-domains}{section.1.1}% 6
\BOOKMARK [2][-]{subsection.1.1.3}{Incompetence of RT to Represent Results in a Graphical Form}{section.1.1}% 7
\BOOKMARK [1][-]{section.1.2}{Research Goals}{chapter.1}% 8
\BOOKMARK [1][-]{section.1.3}{Contributions}{chapter.1}% 9
\BOOKMARK [2][-]{subsection.1.3.1}{Dirt Spot Sweeping Random Strategy}{section.1.3}% 10
\BOOKMARK [2][-]{subsection.1.3.2}{Automated Discovery of Failure Domain}{section.1.3}% 11
\BOOKMARK [2][-]{subsection.1.3.3}{Automated Discovery of Failure Domain+}{section.1.3}% 12
\BOOKMARK [1][-]{section.1.4}{Structure of the Thesis}{chapter.1}% 13
\BOOKMARK [0][-]{chapter.2}{Literature Review}{}% 14
\BOOKMARK [1][-]{section.2.1}{Software Testing}{chapter.2}% 15
\BOOKMARK [1][-]{section.2.2}{Software Testing Levels}{chapter.2}% 16
\BOOKMARK [1][-]{section.2.3}{Software Testing Purpose}{chapter.2}% 17
\BOOKMARK [1][-]{section.2.4}{Software Testing Perspective}{chapter.2}% 18
\BOOKMARK [2][-]{subsection.2.4.1}{White-box Testing}{section.2.4}% 19
\BOOKMARK [2][-]{subsection.2.4.2}{Black-box Testing}{section.2.4}% 20
\BOOKMARK [2][-]{subsection.2.4.3}{Test Case}{section.2.4}% 21
\BOOKMARK [2][-]{subsection.2.4.4}{Test Oracle}{section.2.4}% 22
\BOOKMARK [1][-]{section.2.5}{Forms of Software Testing}{chapter.2}% 23
\BOOKMARK [2][-]{subsection.2.5.1}{Manual Software Testing}{section.2.5}% 24
\BOOKMARK [2][-]{subsection.2.5.2}{Automated Software Testing}{section.2.5}% 25
\BOOKMARK [1][-]{section.2.6}{Test Data Generation}{chapter.2}% 26
\BOOKMARK [2][-]{subsection.2.6.1}{Path-wise Test Data Generators}{section.2.6}% 27
\BOOKMARK [2][-]{subsection.2.6.2}{Goal-oriented Test Data Generators}{section.2.6}% 28
\BOOKMARK [2][-]{subsection.2.6.3}{Intelligent Test Data Generators}{section.2.6}% 29
\BOOKMARK [2][-]{subsection.2.6.4}{Search-based Test Data Generators}{section.2.6}% 30
\BOOKMARK [2][-]{subsection.2.6.5}{Random Test Data Generators}{section.2.6}% 31
\BOOKMARK [1][-]{section.2.7}{Random Testing}{chapter.2}% 32
\BOOKMARK [1][-]{section.2.8}{Input Domain}{chapter.2}% 33
\BOOKMARK [2][-]{subsection.2.8.1}{Genuine and Failure-domain}{section.2.8}% 34
\BOOKMARK [1][-]{section.2.9}{Versions of Random testing}{chapter.2}% 35
\BOOKMARK [2][-]{subsection.2.9.1}{Random+ Testing}{section.2.9}% 36
\BOOKMARK [2][-]{subsection.2.9.2}{Adaptive Random Testing}{section.2.9}% 37
\BOOKMARK [2][-]{subsection.2.9.3}{Mirror Adaptive Random Testing}{section.2.9}% 38
\BOOKMARK [2][-]{subsection.2.9.4}{Restricted Random Testing}{section.2.9}% 39
\BOOKMARK [2][-]{subsection.2.9.5}{Directed Automated Random Testing}{section.2.9}% 40
\BOOKMARK [2][-]{subsection.2.9.6}{Quasi Random Testing}{section.2.9}% 41
\BOOKMARK [2][-]{subsection.2.9.7}{Feedback-directed Random Testing}{section.2.9}% 42
\BOOKMARK [2][-]{subsection.2.9.8}{The Artoo Testing}{section.2.9}% 43
\BOOKMARK [1][-]{section.2.10}{Tools for Automated Random Testing}{chapter.2}% 44
\BOOKMARK [2][-]{subsection.2.10.1}{JCrasher}{section.2.10}% 45
\BOOKMARK [2][-]{subsection.2.10.2}{Jartege}{section.2.10}% 46
\BOOKMARK [2][-]{subsection.2.10.3}{Eclat}{section.2.10}% 47
\BOOKMARK [2][-]{subsection.2.10.4}{Randoop}{section.2.10}% 48
\BOOKMARK [2][-]{subsection.2.10.5}{QuickCheck}{section.2.10}% 49
\BOOKMARK [2][-]{subsection.2.10.6}{AutoTest}{section.2.10}% 50
\BOOKMARK [2][-]{subsection.2.10.7}{TestEra}{section.2.10}% 51
\BOOKMARK [2][-]{subsection.2.10.8}{Korat}{section.2.10}% 52
\BOOKMARK [1][-]{section.2.11}{Summary}{chapter.2}% 53
\BOOKMARK [0][-]{chapter.3}{York Extensible Testing Infrastructure}{}% 54
\BOOKMARK [1][-]{section.3.1}{YETI Overview}{chapter.3}% 55
\BOOKMARK [2][-]{subsection.3.1.1}{YETI Design}{section.3.1}% 56
\BOOKMARK [2][-]{subsection.3.1.2}{Construction of Test Cases}{section.3.1}% 57
\BOOKMARK [2][-]{subsection.3.1.3}{Command-line Options}{section.3.1}% 58
\BOOKMARK [2][-]{subsection.3.1.4}{YETI Execution}{section.3.1}% 59
\BOOKMARK [2][-]{subsection.3.1.5}{YETI Test Oracle}{section.3.1}% 60
\BOOKMARK [2][-]{subsection.3.1.6}{YETI Report}{section.3.1}% 61
\BOOKMARK [2][-]{subsection.3.1.7}{YETI Graphical User Interface}{section.3.1}% 62
\BOOKMARK [2][-]{subsection.3.1.8}{Summary}{section.3.1}% 63
\BOOKMARK [0][-]{chapter.4}{Dirt Spot Sweeping Random Strategy}{}% 64
\BOOKMARK [1][-]{section.4.1}{Introduction}{chapter.4}% 65
\BOOKMARK [1][-]{section.4.2}{Dirt Spot Sweeping Random Strategy}{chapter.4}% 66
\BOOKMARK [2][-]{subsection.4.2.1}{Random Strategy}{section.4.2}% 67
\BOOKMARK [2][-]{subsection.4.2.2}{Random+ Strategy}{section.4.2}% 68
\BOOKMARK [2][-]{subsection.4.2.3}{Dirt Spot Sweeping}{section.4.2}% 69
\BOOKMARK [2][-]{subsection.4.2.4}{Working of DSSR Strategy}{section.4.2}% 70
\BOOKMARK [2][-]{subsection.4.2.5}{Explanation of DSSR Strategy by Example}{section.4.2}% 71
\BOOKMARK [1][-]{section.4.3}{Implementation of DSSR Strategy}{chapter.4}% 72
\BOOKMARK [1][-]{section.4.4}{Evaluation}{chapter.4}% 73
\BOOKMARK [2][-]{subsection.4.4.1}{Research Questions}{section.4.4}% 74
\BOOKMARK [2][-]{subsection.4.4.2}{Experiments}{section.4.4}% 75
\BOOKMARK [2][-]{subsection.4.4.3}{Performance Measurement Criteria}{section.4.4}% 76
\BOOKMARK [1][-]{section.4.5}{Results}{chapter.4}% 77
\BOOKMARK [2][-]{subsection.4.5.1}{Is there an absolute best amongst R, R+ \046 DSSR strategies?}{section.4.5}% 78
\BOOKMARK [2][-]{subsection.4.5.2}{Are there classes for which any of the three strategies provide better results?}{section.4.5}% 79
\BOOKMARK [2][-]{subsection.4.5.3}{Can we pick the best default strategy amongst R, R+ \046 DSSR?}{section.4.5}% 80
\BOOKMARK [1][-]{section.4.6}{Discussion}{chapter.4}% 81
\BOOKMARK [1][-]{section.4.7}{Related Work}{chapter.4}% 82
\BOOKMARK [1][-]{section.4.8}{Conclusions}{chapter.4}% 83
\BOOKMARK [0][-]{chapter.5}{Automated Discovery of Failure Domain}{}% 84
\BOOKMARK [1][-]{section.5.1}{Introduction}{chapter.5}% 85
\BOOKMARK [1][-]{section.5.2}{Automated Discovery of Failure Domain}{chapter.5}% 86
\BOOKMARK [2][-]{subsection.5.2.1}{GUI front-end for Providing Input:}{section.5.2}% 87
\BOOKMARK [2][-]{subsection.5.2.2}{Automated Finding of Fault:}{section.5.2}% 88
\BOOKMARK [2][-]{subsection.5.2.3}{Automated Generation of Modules:}{section.5.2}% 89
\BOOKMARK [2][-]{subsection.5.2.4}{Automated Compilation and Execution of Modules to Discover Domains:}{section.5.2}% 90
\BOOKMARK [2][-]{subsection.5.2.5}{Automated Generation of Graph Showing Domains:}{section.5.2}% 91
\BOOKMARK [1][-]{section.5.3}{Implementation}{chapter.5}% 92
\BOOKMARK [2][-]{subsection.5.3.1}{York Extensible Testing Infrastructure}{section.5.3}% 93
\BOOKMARK [2][-]{subsection.5.3.2}{ADFD strategy in YETI}{section.5.3}% 94
\BOOKMARK [2][-]{subsection.5.3.3}{Example}{section.5.3}% 95
\BOOKMARK [1][-]{section.5.4}{Experimental Results}{chapter.5}% 96
\BOOKMARK [1][-]{section.5.5}{Discussion}{chapter.5}% 97
\BOOKMARK [1][-]{section.5.6}{Threats to Validity}{chapter.5}% 98
\BOOKMARK [1][-]{section.5.7}{Related Works}{chapter.5}% 99
\BOOKMARK [1][-]{section.5.8}{Conclusions}{chapter.5}% 100
\BOOKMARK [0][-]{chapter.6}{Analysis of Failure-Domain by ADFD+ and Daikon}{}% 101
\BOOKMARK [1][-]{section.6.1}{Introduction}{chapter.6}% 102
\BOOKMARK [1][-]{section.6.2}{Preliminaries}{chapter.6}% 103
\BOOKMARK [1][-]{section.6.3}{Automated Discovery of Failure Domain+}{chapter.6}% 104
\BOOKMARK [2][-]{subsection.6.3.1}{Workflow of ADFD+}{section.6.3}% 105
\BOOKMARK [2][-]{subsection.6.3.2}{Implementation of ADFD+}{section.6.3}% 106
\BOOKMARK [2][-]{subsection.6.3.3}{Example to Illustrate Working of ADFD+}{section.6.3}% 107
\BOOKMARK [1][-]{section.6.4}{Daikon}{chapter.6}% 108
\BOOKMARK [1][-]{section.6.5}{Evaluation of Daikon by ADFD+}{chapter.6}% 109
\BOOKMARK [2][-]{subsection.6.5.1}{Research Questions}{section.6.5}% 110
\BOOKMARK [2][-]{subsection.6.5.2}{Experimental Setup}{section.6.5}% 111
\BOOKMARK [1][-]{section.6.6}{Results}{chapter.6}% 112
\BOOKMARK [2][-]{subsection.6.6.1}{Test of One-dimension Programs by ADFD+}{section.6.6}% 113
\BOOKMARK [2][-]{subsection.6.6.2}{Test of One-dimension Programs by Daikon}{section.6.6}% 114
\BOOKMARK [2][-]{subsection.6.6.3}{Test of Two-dimension Programs by ADFD+}{section.6.6}% 115
\BOOKMARK [2][-]{subsection.6.6.4}{Test of Two-dimension Programs by Daikon}{section.6.6}% 116
\BOOKMARK [1][-]{section.6.7}{Discussion}{chapter.6}% 117
\BOOKMARK [1][-]{section.6.8}{Threats to Validity}{chapter.6}% 118
\BOOKMARK [1][-]{section.6.9}{Conclusions}{chapter.6}% 119
\BOOKMARK [1][-]{section.6.10}{Future Work}{chapter.6}% 120
\BOOKMARK [0][-]{chapter.7}{Conclusions}{}% 121
\BOOKMARK [1][-]{section.7.1}{Lessons Learned}{chapter.7}% 122
\BOOKMARK [2][-]{subsection.7.1.1}{Performance measurement criteria may be carefully chosen}{section.7.1}% 123
\BOOKMARK [2][-]{subsection.7.1.2}{Test results of random testing are fluctuating}{section.7.1}% 124
\BOOKMARK [2][-]{subsection.7.1.3}{More computation decreases performance and increases overhead}{section.7.1}% 125
\BOOKMARK [2][-]{subsection.7.1.4}{Starting with random testing and switching to exhaustive strategy helps}{section.7.1}% 126
\BOOKMARK [2][-]{subsection.7.1.5}{Graphical form helps to easily understand the output}{section.7.1}% 127
\BOOKMARK [2][-]{subsection.7.1.6}{Auto-generation of data is simple for primitive types and complicated for reference data types}{section.7.1}% 128
\BOOKMARK [2][-]{subsection.7.1.7}{Graphical representation of multi-argument method and reference data type is complicated}{section.7.1}% 129
\BOOKMARK [2][-]{subsection.7.1.8}{Contracts are helpful in finding failures, used as documentation and oracle}{section.7.1}% 130
\BOOKMARK [0][-]{chapter.8}{Future Work}{}% 131
\BOOKMARK [1][-]{section.8.1}{Introduction}{chapter.8}% 132
\BOOKMARK [2][-]{subsection.8.1.1}{Use of contracts and assertions to find a failure}{section.8.1}% 133
\BOOKMARK [2][-]{subsection.8.1.2}{introducing object distance in DSSR}{section.8.1}% 134
\BOOKMARK [2][-]{subsection.8.1.3}{Measure of the coverage achieved by DSSR, ADFD and ADFD+}{section.8.1}% 135
\BOOKMARK [2][-]{subsection.8.1.4}{Extend ADFD and ADFD+ to test non-numerical and reference type data}{section.8.1}% 136
\BOOKMARK [2][-]{subsection.8.1.5}{Extend ADFD and ADFD+ to represent multi-dimensional programs}{section.8.1}% 137
\BOOKMARK [2][-]{subsection.8.1.6}{Improving the user interface of ADFD+}{section.8.1}% 138
\BOOKMARK [2][-]{subsection.8.1.7}{Evaluating the effectiveness of ADFD+ in real world programs}{section.8.1}% 139
\BOOKMARK [2][-]{subsection.8.1.8}{Characterizing the number of programs containing point, block and strip failure-domains}{section.8.1}% 140
\BOOKMARK [0][-]{appendix.A}{ }{}% 141
\BOOKMARK [1][-]{section.A.1}{Sample code to identify failure domains}{appendix.A}% 142
\BOOKMARK [0][-]{lstnumber.-16.16}{Bibliography}{}% 143
